{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<center><h1>Cap\u00edtulo 3: Voting y persistencia de modelos</h1></center>\n",
      "\n",
      "<h3>Introducci\u00f3n</h3>\n",
      "Vimos en el cap\u00edtulo anterior diferentes m\u00e9todos de aprendizaje y obtuvimos buenos resultados al utilizar una b\u00fasqueda exhaustiva en el espacio de parametros de los clasificadores. Esta b\u00fasqueda exhaustiva nos permiti\u00f3 identificar cuales son los clasificadores que mejor se comportan para resolver nuestro problema de reconocimiento de perros y gatos. En este cap\u00edtulo introduciremos un nuevo clasificador que permite conjugar a los mejores clasificadores del cap\u00edtulo anterior. \n",
      "Adicionalmente, presentaremos las funciones que utilzamos para persistir a disco los estimadores una vez entrenados. Esto es de importancia ya que el entrenamiento de clasificadores con una gran cantidad de instancias y un set de atributos grande, requiere mucho tiempo de procesamiento. Al persistir el clasificador ya entrenado se ahorrar\u00eda este tiempo de entrenamiento durante la competencia."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Clasificaci\u00f3n por Votos</h3>\n",
      "Sklearn implementa [VotingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html), uno de los clasificadores de ensambles m\u00e1s b\u00e1sicos, pero que en muchos casos mejora la performance. La idea detr\u00e1s del estimador por votos es utilizar un conjunto de clasificadores  y combinarlos para sacar provecho de sus bondades y balancear sus debilidades individuales.\n",
      "\n",
      "VotingClassifier(hard) realiza un voto por mayor\u00eda, donde se utiliza la predicci\u00f3n de cada clasificador para obtener la predicci\u00f3n final. VotingClassifier(soft) permite adem\u00e1s asignarle pesos a cada uno de ellos para realizar una votaci\u00f3n teniendo en cuenta estos pesos."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Voting de los mejores clasificadores</h3>\n",
      "En el cap\u00edtulo anterior vimos que un de los mejores set de features era SURF utilizando 300 categor\u00edas y normalizado. Para ese set de features, nos quedaremos con los mejores clasificadores (aquellos con precisi\u00f3n esperada superior al 70%) y que adem\u00e1s priorizando m\u00e9todos conceptualmente diferentes. Utilizaremos entonces los siguientes 5 clasificadores (3 ensambles y 2 no ensambles):\n",
      "<pre>\n",
      "1- LogisticRegression   precisi\u00f3n esperada de 0.774\n",
      "2- SVM                  precisi\u00f3n esperada de 0.758\n",
      "3- GradientBoosting     precisi\u00f3n esperada de 0.728\n",
      "4- Bagging              precisi\u00f3n esperada de 0.712\n",
      "5- RandomForest         precisi\u00f3n esperada de 0.709\n",
      "</pre>\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Estos clasificadores se utilizar\u00e1n parametrizados con el set de parametros encontrado mediante gridsearch. El siguiente extracto de c\u00f3digo (que puede encontrarse en el archivo VotingWithBestEstimators.py) crea un clasificador por votos con estos estimadores, los entrena y luego realiza cross-validation para evaluar su performance.\n",
      "\n",
      "Intentamos reutilizar los clasificadores ya entrenados que obtuvimos en el capitulo anterior, pero no encontramos la forma de evitar tener que reentrenarlos al utilizar Voting. Por lo tanto el clasificador de voting debe reentrenar los clasificadores."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import VotingClassifier\n",
      "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "# Get attributes and class for the images\n",
      "featureSet = 'surf-c300-norm' # 'bp-r5' 'hara-img200'\n",
      "x_data, targets_data = getAttributes(featureSet)\n",
      "\n",
      "# Separate in train & test\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(x_data, targets_data, test_size=0.2, random_state=0)\n",
      "\n",
      "# create the estimators with corresponding parameters\n",
      "estimators = []\n",
      "estimators.append(('LogisticRegression', LogisticRegression(penalty='l2', C=0.005))) # expected 0.774\n",
      "estimators.append(('SVC', SVC(kernel='rbf', C=100, gamma=0.001))) # expected 0.758\n",
      "estimators.append(('GradientBoostingClassifier', GradientBoostingClassifier(n_estimators=150, loss='deviance', learning_rate=0.1, max_depth=3))) # expected 0.728\n",
      "estimators.append(('BaggingClassifier', BaggingClassifier(max_features=0.5, max_samples=0.5, base_estimator=KNeighborsClassifier()))) # expected 0.718\n",
      "estimators.append(('RandomForestClassifier', RandomForestClassifier(max_features=100, n_estimators=100, max_depth=100))) # expected 0.709\n",
      "\n",
      "# Voting\n",
      "voting = VotingClassifier(estimators=estimators, voting='hard');\n",
      "voting.fit(X_train, y_train)\n",
      "voting_prediction = voting.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lo mismo se puede realizar para una votaci\u00f3n pesada, utilizando voting soft utilizando como pesos la precisi\u00f3n esperada da cada clasificador"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "voting = VotingClassifier(estimators=estimators, voting='soft', weights=scores);\n",
      "voting.fit(X_train, y_train)\n",
      "voting_prediction = voting.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Resultados utilizando Voting</h3>\n",
      "Ejecutando VotingWithBestEstimators.py pueden verse los siguentes resultados al utilizar estos clasificadores por votaci\u00f3n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Testing VOTING 'hard' with TEST data:</b>\n",
      "<pre>\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.85      0.73      2475\n",
      "          1       0.78      0.55      0.64      2516\n",
      "\n",
      "avg / total       0.72      0.70      0.69      4991\n",
      "</pre>\n",
      "<pre>\n",
      "Precision:  0.784246575342\n",
      "Recall:  0.546104928458\n",
      "Accuracy:  0.695451813264\n",
      "</pre>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Como puede observarse, el clasificador por votos mejor\u00f3 consiguiendo una precisi\u00f3n mayor a la de todos los clasificadores que lo componen. Es sorprendente ver que este clasificador tiene una precisi\u00f3n de 78%. El accuarcy tambi\u00e9n es bastante alto (de 69%), pero el recall bajo (de 54%)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Persistencia de los modelos </h3>\n",
      "Realizar el entrenamiento de estos modelos conyeba una gran cantidad de tiempo y procesamiento, ya que deben entrenarse todos los clasificadores utilizados para el voting. Adicionalmente, el set de features utilizadas posee 300 atributos, que aumenta el tiempo de entrenamiento.\n",
      "Para resolver este problema, corrimos una vez estos scripts en el server, y una vez termiado guardamos los clasificadores ya entrenados en el disco.\n",
      "A continuaci\u00f3n se detallan los m\u00e9todos utilizados para cargar y persistir clasificadores\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sklear brinda algunos m\u00e9todos para la persistencia de clasificadores: http://scikit-learn.org/stable/modules/model_persistence.html\n",
      "\n",
      "Para nuestro trabajo implementamos la siguiente funci\u00f3n, que adem\u00e1s de persistir el clasificador, guarda tanto sus parametros, como el score esperado. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def saveEstimator(estimator, score, directory):\n",
      "\tif not os.path.exists(directory):\n",
      "\t\tprint(\"created directory: %s \" % directory)\t\n",
      "\t\tos.makedirs(directory)\n",
      "\n",
      "\testimatorName = (\"%s\" % estimator).split('(')[0]\n",
      "\tbaseFileName = os.path.join(directory, estimatorName)\n",
      "\n",
      "\t#save score\n",
      "\twith open(\"%s.score\" % baseFileName, \"w\") as text_file:\n",
      "\t\ttext_file.write(\"%f\\n\" % score)\t\n",
      "\n",
      "\t# write estimator paramas\t\n",
      "\twith open(\"%s.params\" % baseFileName, \"w\") as text_file:\n",
      "\t\ttext_file.write(\"%s\\n\" % estimator)\n",
      "\n",
      "\t#save estimator\n",
      "\tjoblib.dump(estimator, \"%s.pkl\" % baseFileName) \n",
      "\n",
      "\tprint(\"estimator saved to file: %s \" % baseFileName)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Una vez guardados en el disco, estos clasificadores pueden cargarse utilizando la siguiente funci\u00f3n que carga todos los estimadores de un directorio."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def loadEstimators(path):\n",
      "\testimators = []\n",
      "\tfor f in glob.glob(os.path.join(path, '*.pkl')):\n",
      "\t\testimator = joblib.load(f) \n",
      "\n",
      "\t\tbaseFileName = os.path.splitext(f)[0]\n",
      "\t\twith open (\"%s.score\" % baseFileName, \"r\") as scoreFile:\n",
      "\t\t\tscore = float(scoreFile.readline())\n",
      "\t\t\t\n",
      "\n",
      "    \testimators.append((estimator, score))\n",
      "\treturn estimators"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Conclusi\u00f3n\n",
      "-----------\n",
      "\n",
      "En este cap\u00edtulo vimos como utilizando un clasificador por votos la precisi\u00f3n aument\u00f3 hasta un 78%. Adicionalmente, vimos como persistir estos modelos que son costosos para entrenar.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}